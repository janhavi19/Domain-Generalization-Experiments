{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataloading import MultitaskDataset\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pickle\n",
    "import zarr\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_y(x):\n",
    "    mapping = {1: 0, 2: 1, 3: 2, 4: 3}\n",
    "    return mapping.get(x, x)\n",
    "\n",
    "def replace_d(x):\n",
    "    mapping = {2: 0, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8, 11: 9, 13: 10, 14: 11, 15: 12, 16: 13, 17: 14}\n",
    "    return mapping.get(x, x)\n",
    "\n",
    "def loso(X,y,d):\n",
    "    left_out_subject = 14\n",
    "    idx = (d != left_out_subject)\n",
    "    X_train = X[idx]\n",
    "    y_train = y[idx]\n",
    "    d_train = d[idx]\n",
    "\n",
    "    # test data selecting just 14 subject\n",
    "    idxt = (d == left_out_subject)\n",
    "    X_test = X[idxt]\n",
    "    y_test = y[idxt]\n",
    "    d_test = d[idxt]\n",
    "\n",
    "\n",
    "    return X_train, y_train, d_train, X_test, y_test, d_test\n",
    "\n",
    "def data_loader():\n",
    "    zarr_array = zarr.open(\"./dataset/chest_ECG_w60_mw60_ts256_cl2_cs1_fp[1.0].zarr/\", mode=\"r\")\n",
    "    signal = zarr_array['raw_signal'][:]\n",
    "    target_all = zarr_array['target'][:]\n",
    "    subjects_all = zarr_array['subject'][:]\n",
    "\n",
    "    SUBJECTS_IDS = list(range(2, 18))\n",
    "    subjects = SUBJECTS_IDS[:]\n",
    "    classes = [1, 2, 3, 4]\n",
    "\n",
    "    subset_map = [\n",
    "        idx\n",
    "        for idx, i in enumerate(target_all)\n",
    "        if i in classes and subjects_all[idx] in subjects\n",
    "    ]\n",
    "\n",
    "    idx = subset_map\n",
    "    X = signal[idx]\n",
    "    y = target_all[idx]\n",
    "    d = subjects_all[idx]\n",
    "\n",
    "    y_updated = np.vectorize(replace_y)(y)\n",
    "    d_updated = np.vectorize(replace_d)(d)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_updated, test_size=0.33, random_state=42)\n",
    "    \n",
    "    \n",
    "          \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train_scaled).reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test = np.array(X_test_scaled).reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= np.array(y_train).reshape(y_train.shape[0], 1)\n",
    "y_test=np.array(y_test).reshape(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_test,y_test )\n",
    "test_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15061, 1])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECG_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(output_size=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(64, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 64)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = ECG_CNN()\n",
    "\n",
    "# set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Loss: 1.3086\n",
      "Epoch [2], Loss: 1.2623\n",
      "Epoch [3], Loss: 1.2303\n",
      "Epoch [4], Loss: 1.2121\n",
      "Epoch [5], Loss: 1.1978\n",
      "Epoch [6], Loss: 1.1857\n",
      "Epoch [7], Loss: 1.1786\n",
      "Epoch [8], Loss: 1.1696\n",
      "Epoch [9], Loss: 1.1607\n",
      "Epoch [10], Loss: 1.1530\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i in range(X_train.size(0)):\n",
    "        # zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(X_train[i])\n",
    "        # calculate loss\n",
    "        loss = criterion(outputs, y_train[i])\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch [%d], Loss: %.7f' % (epoch+1, running_loss/X_train.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "total_correct = 0\n",
    "total_pred = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_test, y_test in test_loader:\n",
    "        X_test, y_test = X_test, y_test\n",
    "        \n",
    "        outputs = model(X_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(predicted)\n",
    "        total_pred += y_test.size(0)\n",
    "        total_correct += (predicted == y_test).sum().item()\n",
    "\n",
    "accuracy = total_correct / total_pred\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
